{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261bbe4a",
   "metadata": {},
   "source": [
    "# ClaudeCrawl example\n",
    "\n",
    "- Claude 를 이용하여 [Firecrawl](https://firecrawl.dev) 와 비슷하게 동작하도록 하는 ClaudeCrawl 구현\n",
    "- DOM 구조를 몰라도 의미적으로 필요한 정보를 가져올 수 있다.\n",
    "\n",
    "## Install Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b910ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U requests langchain langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb72ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws.chat_models import ChatBedrockConverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1ee54ef0-c9f7-4ea5-806f-f9ed49715e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "# model_id = \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "aws_profile_name = None\n",
    "temperature = 0.1\n",
    "max_tokens = 1024 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ae0f3b19-b95b-465a-bfee-a6214a573417",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatBedrockConverse(\n",
    "    model=model_id,\n",
    "    credentials_profile_name=aws_profile_name,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa2bdacb-0d6d-4f41-8a6b-c263e0846425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article(BaseModel):\n",
    "    \"\"\"Tactic article schema, contains the details of the how to play to win with a specific LOL champion\"\"\"\n",
    "\n",
    "    title: str = Field(\"the title of the article\")\n",
    "    url: str = Field(\"the url link to the article\")\n",
    "    season: int = Field(\"the LOL season number for the article\")\n",
    "    published_at: str = Field(\"published date of the article, RFC 3339 format\")\n",
    "\n",
    "class ExtractSchema(BaseModel):\n",
    "    \"\"\"Schema to extract the articles for the tactics from the page\"\"\"\n",
    "\n",
    "    articles: list[Article] = Field(\"list of the Tactic Article objects in the page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a28d5be-f560-49ce-b947-639358d51bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_output = llm.with_structured_output(ExtractSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "614e894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://lol.inven.co.kr/dataninfo/champion/manualTool.php?confirm=2'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"https://lol.inven.co.kr/dataninfo/champion/manualTool.php?confirm=2\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "40e2461c-445b-4684-affe-97203dbe52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are tasked with scraping information from a web page and extracting specific details based on a given output schema. \n",
    "Your task is to carefully read and analyze the content of this web page, and then extract information according to the provided output schema.\n",
    "\n",
    "## Instruction\n",
    "\n",
    "1. To begin, thoroughly read and analyze the entire web page. \\\n",
    "Pay attention to all sections, including headers, paragraphs, lists, tables, and any other relevant elements. \\\n",
    "Take note of the overall structure and organization of the content.\n",
    "2. As you analyze the page, identify information that matches the fields specified in the output schema. \\\n",
    "Be thorough and precise in your extraction.\n",
    "\n",
    "## HTML Analysis\n",
    "- Examine the HTML code and identify elements, classes, or IDs that correspond to each required data field.\n",
    "- Look for patterns or repeated structures that could indicate multiple items (e.g., product listings).\n",
    "- Note any nested structures or relationships between elements that are relevant to the data extraction task.\n",
    "- Discuss any additional considerations based on the specific HTML layout that are crucial for accurate data extraction.\n",
    "- Recommend the specific strategy to use for scraping the content, remeber.\n",
    "\n",
    "## Data Analysis\n",
    "- List out all the links in the page, to make a group by their similarity.\n",
    "- Meaningful data has a tendency to be around a link url, such as `a` tag.\n",
    "- Article links tends to have similar link url, `href` prop, which out numbers the most of the links in the page.\n",
    "\n",
    "## Link Extraction\n",
    "- Do not create any of links, if the content has no link for the schema. \\\n",
    "In that case, just respond with empty string.\n",
    "\n",
    "Begin your scraping process now, and provide the extracted information in the format specified above.\n",
    "Let's think step by step.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "21a2f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_html(soup):\n",
    "    \"\"\"\n",
    "    HTML에서 불필요하게 중첩된 태그들을 정리하는 함수\n",
    "    \n",
    "    Args:\n",
    "        html_content (str): 정리할 HTML 문자열\n",
    "    \n",
    "    Returns:\n",
    "        str: 정리된 HTML 문자열\n",
    "    \"\"\"\n",
    "    def should_remove_tag(tag):\n",
    "        # 태그가 제거되어야 하는 조건\n",
    "        # 1. 내용이 비어있거나 공백뿐인 경우\n",
    "        # 2. 자식 노드가 하나뿐이고 같은 태그인 경우\n",
    "        if not tag.contents:\n",
    "            return True\n",
    "            \n",
    "        if len(tag.contents) == 1:\n",
    "            child = tag.contents[0]\n",
    "            if isinstance(child, type(tag)) and child.name == tag.name:\n",
    "                return True\n",
    "                \n",
    "        text_content = tag.get_text(strip=True)\n",
    "        if not text_content and len(tag.find_all()) == 0:\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "\n",
    "    def clean_tag(tag):\n",
    "        # 재귀적으로 모든 자식 태그들을 정리\n",
    "        for child in tag.find_all(recursive=False):\n",
    "            clean_tag(child)\n",
    "        \n",
    "        if should_remove_tag(tag):\n",
    "            tag.unwrap()\n",
    "    \n",
    "    # 모든 불필요한 공백 제거\n",
    "    for element in soup(text=lambda text: isinstance(text, str)):\n",
    "        if element.strip() == '':\n",
    "            element.extract()\n",
    "    \n",
    "    # 중첩된 태그 정리\n",
    "    clean_tag(soup)\n",
    "    \n",
    "    # 정리된 HTML 반환\n",
    "    return str(soup)\n",
    "\n",
    "\n",
    "def extract(html:str):\n",
    "    print(\"extract outputs...\")\n",
    "    prompts = ChatPromptTemplate([\n",
    "        (\"system\", SYSTEM_PROMPT),\n",
    "        (\"human\", \"Here is the web page content.\\n```html\\n{html}\\n```\\n\\nPlease extract all the champion tactic articles from the page, 30 articles are placed in the table tag.\"),\n",
    "    ]).invoke({ \"html\": html })\n",
    "    return llm_with_output.invoke(prompts)\n",
    "\n",
    "\n",
    "def clean_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # 완전히 제거할 태그들\n",
    "    tags_to_remove = [\n",
    "        'head',\n",
    "        'script',\n",
    "        'style',\n",
    "        'noscript',\n",
    "        'svg',\n",
    "        'meta',\n",
    "        'iframe'\n",
    "        'link',\n",
    "        'video',\n",
    "        'audio',\n",
    "    ]\n",
    "\n",
    "    # 유지할 속성들\n",
    "    keep_attributes = {\n",
    "        'a': ['href', 'title'],\n",
    "        'div': ['id'],\n",
    "        'span': ['id']\n",
    "    }\n",
    "    \n",
    "    # 제거할 태그들 처리\n",
    "    for tag in tags_to_remove:\n",
    "        for element in soup.find_all(tag):\n",
    "            element.decompose()\n",
    "    \n",
    "    # 모든 요소를 순회하면서 불필요한 속성 제거\n",
    "    for element in soup.find_all():\n",
    "        if element.name in keep_attributes:\n",
    "            # 해당 태그에 대해 유지할 속성 목록\n",
    "            allowed_attrs = keep_attributes[element.name]\n",
    "            # 현재 속성들 중 유지할 속성만 필터링\n",
    "            element.attrs = {k: v for k, v in element.attrs.items() if k in allowed_attrs}\n",
    "        else:\n",
    "            # keep_attributes에 정의되지 않은 태그는 모든 속성 제거\n",
    "            element.attrs = {}\n",
    "        \n",
    "        # 공백 문자열 정리\n",
    "        if element.string:\n",
    "            element.string = ' '.join(element.string.split())\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "def scrape_url(url):\n",
    "    print(f\"scrape url: {url}...\")\n",
    "    downloaded = requests.get(url, timeout=5).content.decode('utf-8')\n",
    "    cleaned_soup = clean_html(downloaded)\n",
    "    flat_html = flatten_html(cleaned_soup)\n",
    "    return extract(flat_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7c738eb5-9400-4ff1-bf72-6d6db8f2b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrape url: https://lol.inven.co.kr/dataninfo/champion/manualTool.php?confirm=2...\n",
      "extract outputs...\n",
      "CPU times: user 232 ms, sys: 8.58 ms, total: 241 ms\n",
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = scrape_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "608c6ab4-ed37-492e-9792-3c38e2401cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Article(title='[GM]AP 샤코 서폿 설명 길게 안함', url='manualToolView.php?idx=146545', season=14, published_at='2023-09-22'),\n",
       " Article(title='★(마스터) 시즌 완벽 적응 개사기 ..', url='manualToolView.php?idx=148044', season=14, published_at='2023-07-26'),\n",
       " Article(title='[GM1]프로 1군원딜들 피셜 근본 원딜..', url='', season=14, published_at='2024-03-16'),\n",
       " Article(title='M)시즌 5부터 딩거 한 유저의 공략', url='manualToolView.php?idx=148020', season=14, published_at='2024-02-05'),\n",
       " Article(title=\"'장인초대석 2회 출연 및 가렌 평점..\", url='manualToolView.php?idx=148003', season=13, published_at='2024-01-09'),\n",
       " Article(title='[M1] 30대중반도 마스터가는잭스공략', url='manualToolView.php?idx=147904', season=13, published_at='2024-01-07'),\n",
       " Article(title='M300) 트페 공략', url='', season=13, published_at='2023-12-30'),\n",
       " Article(title='M1 ) 시즌말에 쓰는 트린다미어 공략', url='', season=13, published_at='2023-10-21'),\n",
       " Article(title='케이틀린', url='manualToolView.php?idx=147527', season=13, published_at='2023-10-06'),\n",
       " Article(title='선제공격 (원형낫 카직스)', url='manualToolView.php?idx=146620', season=13, published_at='2023-06-27'),\n",
       " Article(title='C1)술통 살인사건 미드 그라가스 완..', url='manualToolView.php?idx=147408', season=13, published_at='2023-05-25'),\n",
       " Article(title='[M1] 초보자를 위한 라칸 공략글', url='', season=13, published_at='2023-05-15'),\n",
       " Article(title='[M1] 간단하게 보는 카타리나 공략', url='manualToolView.php?idx=147939', season=13, published_at='2023-04-23'),\n",
       " Article(title='[M1] 이보다 더 완벽한 잔나 공략은..', url='manualToolView.php?idx=146550', season=13, published_at='2023-04-13'),\n",
       " Article(title='[롤][D3] 오른장인이 알려주는 탑 오..', url='', season=13, published_at='2023-04-12'),\n",
       " Article(title='GM 나서스 원챔', url='manualToolView.php?idx=147909', season=13, published_at='2023-03-31'),\n",
       " Article(title='[M1]◉ 시즌13루나미카운터 시야점수..', url='manualToolView.php?idx=147878', season=13, published_at='2024-02-06'),\n",
       " Article(title='시즌13 11/23 프리시즌진행중 모데..', url='manualToolView.php?idx=145898', season=13, published_at='2023-11-28'),\n",
       " Article(title='M1) 디나이 장인 7년산 TOP 다리우스..', url='manualToolView.php?idx=147703', season=12, published_at='2023-10-12'),\n",
       " Article(title='시즌 12) 마스터 아트록스 공략', url='', season=12, published_at='2023-10-10'),\n",
       " Article(title='[D4] 유체화 여진 쉔, 피지컬 안좋은..', url='', season=12, published_at='2023-10-05'),\n",
       " Article(title='[M1 르블랑 1위] ♨ 최강의 딜포터 ..', url='', season=12, published_at='2023-10-03'),\n",
       " Article(title='챌린저 마오카이 서폿 장인 랭킹 1위..', url='', season=12, published_at='2023-09-11'),\n",
       " Article(title='[LOL 시즌12] \"당신이 원하였던 바로..', url='', season=12, published_at='2023-08-03'),\n",
       " Article(title='D3) 애쉬만큼 사기챔피언은 없습니다..', url='manualToolView.php?idx=147752', season=12, published_at='2023-06-27'),\n",
       " Article(title='다1)쉽지만 가장 냉정해야하는 챔프..', url='manualToolView.php?idx=147730', season=12, published_at='2023-06-24'),\n",
       " Article(title='[top] 나서스 12.11', url='manualToolView.php?idx=147133', season=12, published_at='2023-06-11'),\n",
       " Article(title='GM1) 3연속 너프 짜오공략', url='', season=12, published_at='2023-05-22'),\n",
       " Article(title='[D1] 리워크 서폿 소나', url='manualToolView.php?idx=147485', season=12, published_at='2024-03-25')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(response.articles))\n",
    "response.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fb160-3112-4074-80d4-f454ca3ef859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
